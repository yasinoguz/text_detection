# ğŸ“ Text Detection with U-Net

---

An advanced deep learning-based text detection system using **U-Net architecture**, trained on the **ICDAR dataset**.  
This project detects text regions in images with high precision using a combination of **BCE** and **Dice loss functions**.

---

## ğŸ“‹ Features

- ğŸ§  **U-Net Architecture**: Custom implementation of U-Net for semantic segmentation  
- âš–ï¸ **Hybrid Loss Function**: Combines Binary Cross Entropy (BCE) and Dice Loss for better convergence  
- ğŸ§© **Tile-based Processing**: Handles large images by splitting them into manageable tiles  
- ğŸ”„ **Data Augmentation**: Built-in transformations for robust training  
- ğŸ’¾ **Checkpoint System**: Resume training from any point with full state restoration  
- ğŸ–¼ï¸ **Multi-Format Support**: Works with JPG, PNG, BMP images  
- ğŸ“Š **Visualization Tools**: Comprehensive result visualization and analysis  

---

## ğŸ—ï¸ Architecture

### ğŸ”§ Model Structure

```text
UNet Architecture:
â”œâ”€â”€ Encoder (Downsampling)
â”‚   â”œâ”€â”€ DoubleConv(3 â†’ 64)
â”‚   â”œâ”€â”€ MaxPool + DoubleConv(64 â†’ 128)
â”‚   â”œâ”€â”€ MaxPool + DoubleConv(128 â†’ 256)
â”‚   â””â”€â”€ MaxPool + DoubleConv(256 â†’ 512)
â”‚
â”œâ”€â”€ Decoder (Upsampling)
â”‚   â”œâ”€â”€ Upsample + Concat + DoubleConv(512+256 â†’ 256)
â”‚   â”œâ”€â”€ Upsample + Concat + DoubleConv(256+128 â†’ 128)
â”‚   â””â”€â”€ Upsample + Concat + DoubleConv(128+64 â†’ 64)
â”‚
â””â”€â”€ Output Layer
    â””â”€â”€ Conv2d(64 â†’ 1)
âš–ï¸ Loss Function: BCEDiceLoss
text
Kodu kopyala
BCEDiceLoss = bce_weight Ã— BCEWithLogitsLoss + dice_weight Ã— DiceLoss
ğŸŸ¦ BCE: Handles pixel-wise classification

ğŸŸ© Dice: Optimizes for region overlap

ğŸ§® Smooth: Prevents division by zero

ğŸ“ Project Structure
text
Kodu kopyala
text-detection-unet/
â”‚
â”œâ”€â”€ dataset/                    
â”‚   â”œâ”€â”€ ch4_training_images/    
â”‚   â””â”€â”€ ch4_training_localization_transcription_gt/  
â”‚
â”œâ”€â”€ checkpoints/                
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â””â”€â”€ epoch_XX.pth
â”‚
â”œâ”€â”€ results/                    
â”‚   â””â”€â”€ epoch_XX.png
â”‚
â”œâ”€â”€ test_sonuc/                 
â”‚   â””â”€â”€ {image_name}/
â”‚       â”œâ”€â”€ combined_result.png
â”‚       â””â”€â”€ region_XX.png
â”‚
â”œâ”€â”€ Unet.py                     
â”œâ”€â”€ losses.py                   
â”œâ”€â”€ dataset2.py                 
â”œâ”€â”€ train.py                    
â”œâ”€â”€ test.py                     
â””â”€â”€ visualize.py                
ğŸš€ Installation
âœ… Prerequisites
Python 3.8+

PyTorch 1.9+

OpenCV

NumPy

Matplotlib



ğŸ“¦ Install Dependencies
bash
Kodu kopyala
# Clone the repository
git clone https://github.com/yourusername/text-detection-unet.git
cd text-detection-unet

# Install required packages
pip install torch torchvision opencv-python numpy matplotlib shapely tqdm
ğŸ“‚ Dataset Setup
Download the ICDAR 2015 dataset

Place training images in:

awk
Kodu kopyala
dataset/ch4_training_images/
Place ground truth files in:

awk
Kodu kopyala
dataset/ch4_training_localization_transcription_gt/
ğŸƒâ€â™‚ï¸ Usage
ğŸ¯ Training
bash
Kodu kopyala
python train.py
Training Configuration:

Batch Size: 4

Tile Size: 512Ã—512

Stride: 256

Learning Rate: 1e-4

Epochs: 20

Loss: BCEDiceLoss (BCE weight: 0.5, Dice weight: 0.5)

ğŸ” Resume Training
python
Kodu kopyala
resume_pth = "checkpoints/epoch_05.pth"
ğŸ” Testing / Inference
bash
Kodu kopyala
python test.py
Before running, update in test.py:

python
Kodu kopyala
MODEL_PATH = "checkpoints/epoch_05.pth"
IMAGE_PATH = "path/to/your/image.png"
ğŸ“Š Dataset Processing
ğŸ§© Tile Generation
Images are split into overlapping tiles (512Ã—512)

Stride of 256 ensures coverage

Only tiles containing text (IOU > threshold) are used

Padding is applied for edge cases

ğŸ§¾ Annotation Format
text
Kodu kopyala
x1,y1,x2,y2,x3,y3,x4,y4,text
ğŸ­ Mask Creation
Polygons are converted to binary masks

Each tile gets its corresponding mask

ğŸ§  Model Details
ğŸ”¹ DoubleConv Block
Each block contains:

Conv2d (3Ã—3 kernel, padding=1)

Batch Normalization

ReLU Activation

Conv2d (3Ã—3 kernel, padding=1)

Batch Normalization

ReLU Activation

ğŸ“ˆ Performance Metrics
ğŸ“‰ Loss Function
BCE Loss

Dice Loss

Total Loss (weighted combination)

ğŸ“ Evaluation Metrics
IoU

Precision / Recall

F1-Score

ğŸ¯ Inference Pipeline
ğŸ–¼ï¸ Image Preprocessing

ğŸ§  Model Inference

ğŸ§¹ Post-processing

ğŸ“¦ Text Region Detection

ğŸ› ï¸ Customization
ğŸ”§ Modify Training Parameters
python
Kodu kopyala
NUM_EPOCHS = 50
BATCH_SIZE = 8
LEARNING_RATE = 0.0001
TILE_SIZE = 640
STRIDE = 320
âš–ï¸ Custom Loss Weights
python
Kodu kopyala
criterion = BCEDiceLoss(bce_weight=0.7, dice_weight=0.3)
ğŸšï¸ Adjust Detection Thresholds
python
Kodu kopyala
threshold = 0.5
min_area = 50
ğŸ“ Results
combined_result.png

region_XX.png

Includes:

Original image

Prediction heatmap

Detected text regions

Cropped text regions

ğŸ”§ Troubleshooting
âŒ CUDA Out of Memory
python
Kodu kopyala
dataloader = DataLoader(dataset, batch_size=2, ...)
âŒ Empty Training Set
Check dataset paths

Verify IOU threshold

Match image & text files

âŒ Poor Detection Results
Increase epochs

Adjust loss weights

Add augmentation

ğŸ“š References

ICDAR 2015 Dataset

PyTorch Documentation



        eÄŸitim 
![eÄŸitim gÃ¶rseli ](images/3.png)

        eÄŸitim 
![eÄŸitim gÃ¶rseli ](images/2.png)

        test
![test gÃ¶rseli ](images/1.png)



