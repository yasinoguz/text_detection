# üöÄ Text Detection with U-Net

An advanced deep learning-based text detection system using U-Net architecture, trained on the ICDAR dataset. This project detects text regions in images with high precision using a combination of BCE and Dice loss functions.

üìã Features
U-Net Architecture: Custom implementation of U-Net for semantic segmentation

Hybrid Loss Function: Combines Binary Cross Entropy (BCE) and Dice Loss for better convergence

Tile-based Processing: Handles large images by splitting them into manageable tiles

Data Augmentation: Built-in transformations for robust training

Checkpoint System: Resume training from any point with full state restoration

Multi-Format Support: Works with JPG, PNG, BMP images

Visualization Tools: Comprehensive result visualization and analysis: Morfolojik i≈ülemler ve kontur analizi


üèóÔ∏è Architecture
Model Structure
text
UNet Architecture:
‚îú‚îÄ‚îÄ Encoder (Downsampling)
‚îÇ   ‚îú‚îÄ‚îÄ DoubleConv(3 ‚Üí 64)
‚îÇ   ‚îú‚îÄ‚îÄ MaxPool + DoubleConv(64 ‚Üí 128)
‚îÇ   ‚îú‚îÄ‚îÄ MaxPool + DoubleConv(128 ‚Üí 256)
‚îÇ   ‚îî‚îÄ‚îÄ MaxPool + DoubleConv(256 ‚Üí 512)
‚îÇ
‚îú‚îÄ‚îÄ Decoder (Upsampling)
‚îÇ   ‚îú‚îÄ‚îÄ Upsample + Concat + DoubleConv(512+256 ‚Üí 256)
‚îÇ   ‚îú‚îÄ‚îÄ Upsample + Concat + DoubleConv(256+128 ‚Üí 128)
‚îÇ   ‚îî‚îÄ‚îÄ Upsample + Concat + DoubleConv(128+64 ‚Üí 64)
‚îÇ
‚îî‚îÄ‚îÄ Output Layer
    ‚îî‚îÄ‚îÄ Conv2d(64 ‚Üí 1)
Loss Function: BCEDiceLoss
text
BCEDiceLoss = bce_weight √ó BCEWithLogitsLoss + dice_weight √ó DiceLoss
- BCE: Handles pixel-wise classification
- Dice: Optimizes for region overlap
- Smooth: Prevents division by zero
üìÅ Project Structure
text
text-detection-unet/
‚îÇ
‚îú‚îÄ‚îÄ dataset/                    # Dataset directory (not included in repo)
‚îÇ   ‚îú‚îÄ‚îÄ ch4_training_images/    # Training images
‚îÇ   ‚îî‚îÄ‚îÄ ch4_training_localization_transcription_gt/  # Ground truth annotations
‚îÇ
‚îú‚îÄ‚îÄ checkpoints/                # Model checkpoints
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pth
‚îÇ   ‚îî‚îÄ‚îÄ epoch_XX.pth
‚îÇ
‚îú‚îÄ‚îÄ results/                    # Training results and visualizations
‚îÇ   ‚îî‚îÄ‚îÄ epoch_XX.png
‚îÇ
‚îú‚îÄ‚îÄ test_sonuc/                 # Test results with detected regions
‚îÇ   ‚îî‚îÄ‚îÄ {image_name}/
‚îÇ       ‚îú‚îÄ‚îÄ combined_result.png
‚îÇ       ‚îî‚îÄ‚îÄ region_XX.png
‚îÇ
‚îú‚îÄ‚îÄ Unet.py                     # U-Net model implementation
‚îú‚îÄ‚îÄ losses.py                   # Loss functions (BCEDiceLoss)
‚îú‚îÄ‚îÄ dataset2.py                 # Dataset loader and tile processing
‚îú‚îÄ‚îÄ train.py                    # Training script with resume capability
‚îú‚îÄ‚îÄ test.py                     # Testing and inference script
‚îî‚îÄ‚îÄ visualize.py                # Visualization utilities



üöÄ Installation
Prerequisites
Python 3.8+

PyTorch 1.9+

OpenCV

NumPy

Matplotlib


Install Dependencies
bash
# Clone the repository
git clone https://github.com/yourusername/text-detection-unet.git
cd text-detection-unet

# Install required packages
pip install torch torchvision opencv-python numpy matplotlib shapely tqdm
Dataset Setup
Download the ICDAR 2015 dataset

Place the training images in dataset/ch4_training_images/

Place the ground truth text files in dataset/ch4_training_localization_transcription_gt/

üèÉ‚Äç‚ôÇÔ∏è Usage
Training
bash
python train.py
Training Configuration:

Batch Size: 4

Tile Size: 512√ó512

Stride: 256

Learning Rate: 1e-4

Epochs: 20

Loss: BCEDiceLoss (BCE weight: 0.5, Dice weight: 0.5)


Resume Training:

python
# In train.py, set the resume path:
resume_pth = "checkpoints/epoch_05.pth"
Testing/Inference
bash
python test.py
Before running, update in test.py:

python
MODEL_PATH = "checkpoints/epoch_05.pth"  # Path to your model checkpoint
IMAGE_PATH = "path/to/your/image.png"    # Path to test image
üìä Dataset Processing
Tile Generation
Images are split into overlapping tiles (512√ó512)

Stride of 256 ensures coverage while maintaining context

Only tiles containing text (IOU > threshold) are used for training

Padding is applied to handle edge cases


Mask Creation
Polygons are converted to binary masks

Each tile gets its corresponding mask for supervised training

üß† Model Details
DoubleConv Block
Each convolutional block contains:

Conv2d (3√ó3 kernel, padding=1)

Batch Normalization

ReLU Activation

Conv2d (3√ó3 kernel, padding=1)

Batch Normalization

ReLU Activation

Training Features
Learning Rate Scheduling: ReduceLROnPlateau with factor=0.5, patience=2

Checkpointing: Saves model after each epoch

Best Model Tracking: Automatically saves the best model based on validation loss

Visualization: Saves sample predictions after each epoch

Resume Capability: Can continue training from any checkpoint

üìà Performance Metrics
Loss Function
BCE Loss: Measures pixel-wise classification error

Dice Loss: Measures region overlap (1 - Dice coefficient)

Total Loss: Weighted combination of both losses

Evaluation Metrics
Intersection over Union (IoU): For segmentation quality

Precision/Recall: For text detection accuracy

F1-Score: Balance between precision and recall

üéØ Inference Pipeline
Step-by-Step Process:
Image Preprocessing

Read and convert to RGB

Pad to make dimensions divisible by tile size

Split into overlapping tiles

Model Inference

Process each tile through U-Net

Apply sigmoid activation

Generate probability maps

Post-processing

Reconstruct full image from tile predictions

Apply weighted averaging for smooth transitions

Threshold to create binary mask

Apply morphological operations

Text Region Detection

Find contours in binary mask

Filter by area and aspect ratio

Extract bounding boxes

Save individual text regions

üõ†Ô∏è Customization
Modify Training Parameters
python
# In train.py
NUM_EPOCHS = 50
BATCH_SIZE = 8
LEARNING_RATE = 0.0001
TILE_SIZE = 640
STRIDE = 320
Custom Loss Weights
python
# In train.py
criterion = BCEDiceLoss(bce_weight=0.7, dice_weight=0.3)
Adjust Text Detection Thresholds
python
# In test.py
threshold = 0.5  # Binary threshold
min_area = 50    # Minimum text region area
üìù Results
Output Structure
After testing, results are saved in test_sonuc/{image_name}/:

combined_result.png: Side-by-side comparison

region_XX.png: Individual detected text regions

Visualization
The system provides:

Original image

Prediction heatmap

Detected text regions with bounding boxes

Individual cropped text regions

üîß Troubleshooting
Common Issues
CUDA Out of Memory

python
# Reduce batch size in train.py
dataloader = DataLoader(dataset, batch_size=2, ...)
Empty Training Set

Check dataset paths

Verify IOU threshold in dataset2.py

Ensure text files match image files

Poor Detection Results

Increase training epochs

Adjust loss weights

Add data augmentation

Try different threshold values

Slow Inference

Increase tile stride

Reduce image resolution

Use GPU acceleration

üìö References
U-Net: Convolutional Networks for Biomedical Image Segmentation

ICDAR 2015 Dataset

PyTorch Documentation



        eƒüitim 
![eƒüitim g√∂rseli ](images/3.png)

        eƒüitim 
![eƒüitim g√∂rseli ](images/2.png)

        test
![test g√∂rseli ](images/1.png)



